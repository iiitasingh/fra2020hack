#From Production base image\nFROM pc-container-registry.ubs.net/ubs/risklab/dominodatalab/base:Ubuntu18_minimal_py37\n\n#Installing requirements from requirements.txt\nCOPY requirements.txt /tmp\nRUN pip install -U pip \\\n&& pip install -r /tmp/requirements.txt && \\\nrm -Rf /root/.cache\n# Additional Docker instructions from mock interface\n RUN mkdir -p /tmp && \\\nwget -q --no-check-certificate -p /tmp/ https:// nexux-write.1dn.swissbank.com/nexux/content/repositories/deploy-ib-shared-003-release/com/ubs/fsp/edge-spark/2.4.5/edge-spark-2.4.5.tgz && \\\nmkdir /opt/model && \\\ntar -xzf /tmp/edge-spark-2.4.5.tgz -C /opt/model/ && \\\nsed -i 's/\r//g' /opt/model/edge-spark-2.4.5-bin-hadoop3.2.1/bin/* && \\\nwget -q --no-check-certificate -P /opt/model/ https:// nexux-write.1dn.swissbank.com/nexus/content/repositories/deploy-ib-shared-003-release/com/ubs/megdp/frp/edge_base_moniker/0.0.1/edge_base_moniker-0.0..1.jar && \\\nrm -Rf /tmp && \\\nconda install openjdk -y && \\\nrm -R /opt/conda/pkgs -f\n#Setting up the environment\nENV SPARK_HOME /opt/model/edge-spark-2.4.5-bin-hadoop3.2.1\nENV JAVA-HOME=/opt/conda/jre\nENV PYTHONPATH=${SPARK_HOME}/python\n ENV PYSPARK_PYTHON ${SPARK_HOME}\n ENV PYSPARK_DRIVER_PYTHON ${SPARK_HOME}\nENV PYTHONPATH $SPARK_HOME/python/lib/py4j-0.10.7-src.zip:$PYTHONPATH\nENV HADOOP_HOME ${SPARK_HOME}\nENV PYSPARK_SUBMIT_ARGS="--master local --jars /opt/model/edge_base_moniker-*.jar pyspark-shell"\n#MEG connection variables\nENV AZURE_CLIENT_ID=<masked>\nENV AZURE_CLIENT_SECRET=<masked>\nENV AZURE_TENANT_ID=<masked>\nENV KEY_VAULT_NAME=<masked>\n\n#Setting up the workspace\nCOPY src src\n